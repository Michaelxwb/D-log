import time
import threading
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

from .monitor import DockerLogMonitor
from .ssh_manager import RemoteDockerManager, SSHConnectionPool
from utils.logger import setup_logger


class RemoteDockerLogMonitor(DockerLogMonitor):
    """è¿œç¨‹Dockeræ—¥å¿—ç›‘æ§å™¨"""
    
    def __init__(self, config, server_config: Dict[str, Any]):
        super().__init__(config)
        self.server_config = server_config
        self.server_name = server_config.get('name', server_config['host'])
        self.remote_manager = None
        self.logger = setup_logger()
    
    def set_remote_manager(self, remote_manager: RemoteDockerManager):
        """è®¾ç½®è¿œç¨‹ç®¡ç†å™¨"""
        self.remote_manager = remote_manager
    
    def get_container_logs(self, container_name: str, since=None) -> List[str]:
        """è·å–è¿œç¨‹å®¹å™¨æ—¥å¿—"""
        if not self.remote_manager:
            return []
        
        # å¤„ç†sinceå‚æ•°
        since_str = None
        if since:
            if isinstance(since, (int, float)):
                # Unixæ—¶é—´æˆ³è½¬æ¢ä¸ºç›¸å¯¹æ—¶é—´
                since_seconds = int(time.time() - since)
                since_str = f"{since_seconds}s"
            elif isinstance(since, str):
                since_str = since
        
        return self.remote_manager.get_container_logs(
            self.server_config, 
            container_name, 
            since=since_str
        )
    
    def get_monitored_containers(self) -> List[str]:
        """è·å–éœ€è¦ç›‘æ§çš„å®¹å™¨åˆ—è¡¨"""
        containers = self.server_config.get('containers', [])
        
        if not containers and self.remote_manager:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šå®¹å™¨ï¼Œè·å–æ‰€æœ‰è¿è¡Œä¸­çš„å®¹å™¨
            containers = self.remote_manager.get_running_containers(self.server_config)
        
        # è¿‡æ»¤é»‘åå•å®¹å™¨
        blacklist = self.config.get('blacklist', {})
        blacklisted_containers = blacklist.get('containers', [])
        containers = [c for c in containers if c not in blacklisted_containers]
        
        return containers
    
    def process_container_logs(self, container_name: str) -> List[Dict[str, Any]]:
        """å¤„ç†å®¹å™¨æ—¥å¿—å¹¶è¿”å›é”™è¯¯ä¿¡æ¯"""
        logs = self.get_container_logs_since(container_name)
        if not logs:
            return []
        
        # æ·»åŠ åˆ°ç¼“å†²åŒº
        if container_name not in self.log_buffer:
            self.log_buffer[container_name] = []
        
        self.log_buffer[container_name].extend(logs)
        
        # é™åˆ¶ç¼“å†²åŒºå¤§å°
        if len(self.log_buffer[container_name]) > self.buffer_size:
            self.log_buffer[container_name] = self.log_buffer[container_name][-self.buffer_size:]
        
        errors = []
        processed_indices = set()
        
        for i, log_line in enumerate(self.log_buffer[container_name]):
            if i in processed_indices:
                continue
                
            if self.should_notify(container_name, log_line):
                error_key = f"{self.server_name}:{self.get_error_key(container_name, log_line)}"
                
                should_send, current_count = self.can_send_notification(error_key)
                if should_send:
                    start_idx, end_idx = self.find_error_boundaries(
                        self.log_buffer[container_name], i
                    )
                    
                    error_context = self.aggregate_error_context(
                        container_name, self.log_buffer[container_name], start_idx
                    )
                    
                    # æ ‡è®°å·²å¤„ç†
                    for idx in range(start_idx, min(end_idx, len(self.log_buffer[container_name]))):
                        processed_indices.add(idx)
                    
                    threshold = self.config.get('error_threshold', 3)
                    
                    errors.append({
                        'server': self.server_name,
                        'container': container_name,
                        'context': error_context,
                        'count': current_count,
                        'threshold': threshold,
                        'timestamp': datetime.now(timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S CST')
                    })
        
        # æ¸…ç†å·²å¤„ç†çš„æ—¥å¿—
        self.log_buffer[container_name] = [
            log for i, log in enumerate(self.log_buffer[container_name]) 
            if i not in processed_indices
        ]
        
        return errors


class MultiServerMonitor:
    """å¤šæœåŠ¡å™¨ç›‘æ§å™¨"""
    
    def __init__(self, config):
        self.config = config
        self.ssh_pool = SSHConnectionPool(
            max_connections=config.get('ssh_settings.max_connections', 5),
            pool_size=config.get('ssh_settings.connection_pool_size', 3)
        )
        self.remote_manager = RemoteDockerManager(self.ssh_pool)
        self.monitors: Dict[str, RemoteDockerLogMonitor] = {}
        self.logger = setup_logger()
        self._setup_monitors()
    
    def _setup_monitors(self):
        """è®¾ç½®è¿œç¨‹ç›‘æ§å™¨"""
        remote_servers = self.config.get('remote_servers', [])
        
        for server_config in remote_servers:
            server_name = server_config.get('name', server_config['host'])
            
            # æ£€æŸ¥Dockerå¯ç”¨æ€§
            if self.remote_manager.check_docker_availability(server_config):
                monitor = RemoteDockerLogMonitor(self.config, server_config)
                monitor.set_remote_manager(self.remote_manager)
                self.monitors[server_name] = monitor
                self.logger.info(f"âœ… å·²æ·»åŠ è¿œç¨‹æœåŠ¡å™¨ç›‘æ§: {server_name}")
            else:
                self.logger.warning(f"âš ï¸ è·³è¿‡ä¸å¯ç”¨æœåŠ¡å™¨: {server_name}")
    
    def process_all_servers(self) -> List[Dict[str, Any]]:
        """å¤„ç†æ‰€æœ‰æœåŠ¡å™¨çš„æ—¥å¿—"""
        all_errors = []
        
        if not self.monitors:
            return all_errors
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†å¤šä¸ªæœåŠ¡å™¨
        max_workers = min(len(self.monitors), 5)
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_server = {}
            
            for server_name, monitor in self.monitors.items():
                containers = monitor.get_monitored_containers()
                
                for container_name in containers:
                    future = executor.submit(monitor.process_container_logs, container_name)
                    future_to_server[future] = (server_name, container_name)
            
            for future in as_completed(future_to_server):
                server_name, container_name = future_to_server[future]
                try:
                    errors = future.result()
                    all_errors.extend(errors)
                except Exception as e:
                    self.logger.error(f"å¤„ç†æœåŠ¡å™¨ {server_name} å®¹å™¨ {container_name} æ—¥å¿—å¤±è´¥: {e}")
        
        return all_errors
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.ssh_pool.close_all_connections()
        self.logger.info("ğŸ§¹ å·²æ¸…ç†æ‰€æœ‰SSHè¿æ¥")